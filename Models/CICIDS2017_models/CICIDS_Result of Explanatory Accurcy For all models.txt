
================================================================================
EVALUATING EXPLANATORY POWER For Decision Tree Model
================================================================================

======================================================================
EXPLANATION ACCURACY EVALUATION - SUMMARY REPORT
======================================================================

Dataset: DT CICIDS2017 Dataset
Samples: 1000
Features: 76

----------------------------------------------------------------------
MAIN RESULTS (Full Dataset)
----------------------------------------------------------------------

LIME:
  k=5: 0.730 ± 0.306 [95% CI: 0.711, 0.749]
  k=10: 0.790 ± 0.290 [95% CI: 0.770, 0.807]
  k=15: 0.812 ± 0.270 [95% CI: 0.795, 0.829]
  k=20: 0.802 ± 0.271 [95% CI: 0.784, 0.819]

SHAP:
  k=5: 0.848 ± 0.268 [95% CI: 0.831, 0.864]
  k=10: 0.875 ± 0.239 [95% CI: 0.859, 0.888]
  k=15: 0.899 ± 0.227 [95% CI: 0.884, 0.912]
  k=20: 0.895 ± 0.230 [95% CI: 0.880, 0.909]

----------------------------------------------------------------------
STATISTICAL VALIDATION
----------------------------------------------------------------------

LIME:
  Mean Faithfulness: 0.732 ± 0.286
  95% CI: [0.714, 0.749]
  vs Random: 0.120 (p=0.0005)
  vs Least: 0.000 (p=0.0005)
  Deletion 1-AUC: 0.664
  Spearman ρ: 0.265

SHAP:
  Mean Faithfulness: 0.707 ± 0.343
  95% CI: [0.685, 0.727]
  vs Random: 0.120 (p=0.0005)
  vs Least: 0.000 (p=0.0005)
  Deletion 1-AUC: 0.692
  Spearman ρ: 0.325

----------------------------------------------------------------------
INTERPRETATION
----------------------------------------------------------------------

1. Both methods significantly outperform random and least-important
   baselines (p < 0.001), confirming causal faithfulness.

2. LIME shows higher faithfulness (0.707 vs 0.732),
   indicating better alignment with model behavior.

3. Positive Spearman correlation and deletion AUC confirm that
   identified important features causally impact predictions.

4. Results are statistically robust with tight confidence intervals.



================================================================================
EVALUATING EXPLANATORY POWER For Random Forest Model
================================================================================

======================================================================
EXPLANATION ACCURACY EVALUATION - SUMMARY REPORT
======================================================================

Dataset: RF CICIDS2017 Dataset
Samples: 1000
Features: 76

----------------------------------------------------------------------
MAIN RESULTS (Full Dataset)
----------------------------------------------------------------------

LIME:
  k=5: 0.151 ± 0.250 [95% CI: 0.136, 0.167]
  k=10: 0.404 ± 0.424 [95% CI: 0.378, 0.431]
  k=15: 0.550 ± 0.422 [95% CI: 0.524, 0.576]
  k=20: 0.683 ± 0.396 [95% CI: 0.658, 0.707]

SHAP:
  k=5: 0.223 ± 0.299 [95% CI: 0.205, 0.243]
  k=10: 0.429 ± 0.425 [95% CI: 0.402, 0.456]
  k=15: 0.629 ± 0.391 [95% CI: 0.604, 0.654]
  k=20: 0.771 ± 0.395 [95% CI: 0.746, 0.795]

----------------------------------------------------------------------
STATISTICAL VALIDATION
----------------------------------------------------------------------

LIME:
  Mean Faithfulness: 0.108 ± 0.217
  95% CI: [0.094, 0.122]
  vs Random: 0.003 (p=0.0005)
  vs Least: 0.000 (p=0.0005)
  Deletion 1-AUC: 0.246
  Spearman ρ: 0.423

SHAP:
  Mean Faithfulness: 0.283 ± 0.310
  95% CI: [0.263, 0.302]
  vs Random: 0.003 (p=0.0005)
  vs Least: 0.000 (p=0.0005)
  Deletion 1-AUC: 0.280
  Spearman ρ: 0.517

----------------------------------------------------------------------
INTERPRETATION
----------------------------------------------------------------------

1. Both methods significantly outperform random and least-important
   baselines (p < 0.001), confirming causal faithfulness.

2. SHAP shows higher faithfulness (0.283 vs 0.108),
   indicating better alignment with model behavior.

3. Positive Spearman correlation and deletion AUC confirm that
   identified important features causally impact predictions.

4. Results are statistically robust with tight confidence intervals.








================================================================================
EVALUATING EXPLANATORY POWER For Logistic Regression 
================================================================================

======================================================================
EXPLANATION ACCURACY EVALUATION - SUMMARY REPORT
======================================================================

Dataset: LR CICIDS2017 Dataset
Samples: 1000
Features: 76

----------------------------------------------------------------------
MAIN RESULTS (Full Dataset)
----------------------------------------------------------------------

LIME:
  k=5: 0.679 ± 0.329 [95% CI: 0.659, 0.699]
  k=10: 0.865 ± 0.240 [95% CI: 0.850, 0.880]
  k=15: 0.892 ± 0.210 [95% CI: 0.880, 0.905]
  k=20: 0.910 ± 0.197 [95% CI: 0.898, 0.923]

SHAP:
  k=5: 0.818 ± 0.260 [95% CI: 0.801, 0.834]
  k=10: 0.975 ± 0.091 [95% CI: 0.969, 0.980]
  k=15: 0.965 ± 0.105 [95% CI: 0.958, 0.971]
  k=20: 0.963 ± 0.106 [95% CI: 0.956, 0.969]

----------------------------------------------------------------------
STATISTICAL VALIDATION
----------------------------------------------------------------------

LIME:
  Mean Faithfulness: 0.813 ± 0.249
  95% CI: [0.798, 0.828]
  vs Random: 0.345 (p=0.0005)
  vs Least: 0.000 (p=0.0005)
  Deletion 1-AUC: 0.701
  Spearman ρ: 0.156

SHAP:
  Mean Faithfulness: 0.849 ± 0.189
  95% CI: [0.838, 0.861]
  vs Random: 0.345 (p=0.0005)
  vs Least: 0.000 (p=0.0005)
  Deletion 1-AUC: 0.634
  Spearman ρ: 0.258

----------------------------------------------------------------------
INTERPRETATION
----------------------------------------------------------------------

1. Both methods significantly outperform random and least-important
   baselines (p < 0.001), confirming causal faithfulness.

2. SHAP shows higher faithfulness (0.849 vs 0.813),
   indicating better alignment with model behavior.

3. Positive Spearman correlation and deletion AUC confirm that
   identified important features causally impact predictions.

4. Results are statistically robust with tight confidence intervals.





================================================================================
EVALUATING EXPLANATORY POWER For XGBoost Model 
================================================================================

======================================================================
EXPLANATION ACCURACY EVALUATION - SUMMARY REPORT
======================================================================

Dataset: XGBoost CICIDS2017 Dataset
Samples: 1000
Features: 76

----------------------------------------------------------------------
MAIN RESULTS (Full Dataset)
----------------------------------------------------------------------

LIME:
  k=5: 0.421 ± 0.435 [95% CI: 0.394, 0.448]
  k=10: 0.517 ± 0.431 [95% CI: 0.491, 0.545]
  k=15: 0.554 ± 0.408 [95% CI: 0.529, 0.579]
  k=20: 0.587 ± 0.399 [95% CI: 0.562, 0.613]

SHAP:
  k=5: 0.720 ± 0.394 [95% CI: 0.694, 0.744]
  k=10: 0.812 ± 0.323 [95% CI: 0.791, 0.831]
  k=15: 0.855 ± 0.280 [95% CI: 0.837, 0.872]
  k=20: 0.847 ± 0.299 [95% CI: 0.827, 0.864]

----------------------------------------------------------------------
STATISTICAL VALIDATION
----------------------------------------------------------------------

LIME:
  Mean Faithfulness: 0.435 ± 0.449
  95% CI: [0.406, 0.462]
  vs Random: 0.058 (p=0.0005)
  vs Least: 0.000 (p=0.0005)
  Deletion 1-AUC: 0.880
  Spearman ρ: 0.186

SHAP:
  Mean Faithfulness: 0.631 ± 0.358
  95% CI: [0.608, 0.652]
  vs Random: 0.058 (p=0.0005)
  vs Least: 0.005 (p=0.0005)
  Deletion 1-AUC: 0.896
  Spearman ρ: 0.327

----------------------------------------------------------------------
INTERPRETATION
----------------------------------------------------------------------

1. Both methods significantly outperform random and least-important
   baselines (p < 0.001), confirming causal faithfulness.

2. SHAP shows higher faithfulness (0.631 vs 0.435),
   indicating better alignment with model behavior.

3. Positive Spearman correlation and deletion AUC confirm that
   identified important features causally impact predictions.

4. Results are statistically robust with tight confidence intervals.

